<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>AI Meeting Notes Agent</title>
    <style>
        body {
            font-family: 'Segoe UI', Tahoma, Geneva, Verdana, sans-serif;
            margin: 0;
            padding: 20px;
            background-color: #f5f5f5;
        }
        .container {
            max-width: 1200px;
            margin: 0 auto;
            background: white;
            border-radius: 10px;
            box-shadow: 0 2px 10px rgba(0,0,0,0.1);
            overflow: hidden;
        }
        .header {
            background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
            color: white;
            padding: 20px;
            text-align: center;
        }
        .controls {
            padding: 20px;
            border-bottom: 1px solid #eee;
            display: flex;
            gap: 10px;
            align-items: center;
        }
        .meeting-info {
            display: flex;
            gap: 10px;
            align-items: center;
        }
        input, button {
            padding: 10px;
            border: 1px solid #ddd;
            border-radius: 5px;
            font-size: 14px;
        }
        button {
            background: #667eea;
            color: white;
            border: none;
            cursor: pointer;
            transition: background 0.3s;
        }
        button:hover {
            background: #5a6fd8;
        }
        button.recording {
            background: #e74c3c;
        }
        button.recording:hover {
            background: #c0392b;
        }
        .content {
            display: flex;
            height: 600px;
        }
        .transcript-panel, .notes-panel {
            flex: 1;
            padding: 20px;
            border-right: 1px solid #eee;
            overflow-y: auto;
        }
        .notes-panel {
            border-right: none;
        }
        .transcript-item, .note-item {
            margin-bottom: 15px;
            padding: 10px;
            background: #f8f9fa;
            border-radius: 5px;
            border-left: 4px solid #667eea;
        }
        .note-item.summary {
            border-left-color: #28a745;
            background: #d4edda;
        }
        .timestamp {
            color: #666;
            font-size: 12px;
            margin-bottom: 5px;
        }
        .speaker {
            font-weight: bold;
            color: #667eea;
        }
        .status {
            padding: 10px;
            background: #e9ecef;
            text-align: center;
            font-weight: bold;
        }
        .status.recording {
            background: #f8d7da;
            color: #721c24;
        }
        .status.info {
            background: #e9f7ef;
            color: #155724;
        }
        .status.error {
            background: #f8d7da;
            color: #721c24;
        }
        .interim {
            font-style: italic;
            color: #6c757d;
            padding: 8px 12px;
            margin-bottom: 10px;
            border-left: 3px dashed #6c757d;
            background: #fff;
            border-radius: 4px;
        }
    </style>
</head>
<body>
    <div class="container">
        <div class="header">
            <h1>ü§ñ AI Meeting Notes Agent</h1>
            <p>Real-time transcription and summarization for online meetings</p>
        </div>

        <div class="controls">
            <div class="meeting-info">
                <input type="text" id="meetingTitle" placeholder="Meeting Title" value="Meeting">
                <button id="startMeeting">Start Meeting</button>
            </div>
            <button id="toggleRecording">üé§ Start Recording</button>
            <button id="generateSummary">üìù Generate Summary</button>
            <button id="exportTranscript">üì• Export Transcript</button>
            <button id="exportNotes">üíæ Export Notes</button>
        </div>

        <div id="status" class="status">Ready to start meeting</div>

        <div class="content">
            <div class="transcript-panel">
                <h3>üìù Live Transcript</h3>
                <div id="interim" class="interim" aria-live="polite" hidden></div>
                <div id="transcript"></div>
            </div>
            <div class="notes-panel">
                <h3>üìã Meeting Notes</h3>
                <div id="notes"></div>
            </div>
        </div>
    </div>

    <script>
        let websocket = null;
        let isRecording = false;
        let mediaRecorder = null;
        let audioChunks = [];

        // DOM elements
        const meetingTitle = document.getElementById('meetingTitle');
        const startMeetingBtn = document.getElementById('startMeeting');
        const toggleRecordingBtn = document.getElementById('toggleRecording');
        const generateSummaryBtn = document.getElementById('generateSummary');
        const exportTranscriptBtn = document.getElementById('exportTranscript');
        const exportNotesBtn = document.getElementById('exportNotes');
        const statusDiv = document.getElementById('status');
        const transcriptDiv = document.getElementById('transcript');
        const notesDiv = document.getElementById('notes');

        // Initialize speech recognition (Web Speech API)
        let recognition = null;
        if (typeof window !== 'undefined' && (window.SpeechRecognition || window.webkitSpeechRecognition)) {
            const SpeechRecognition = window.SpeechRecognition || window.webkitSpeechRecognition;
            recognition = new SpeechRecognition();
            recognition.continuous = true;
            recognition.interimResults = true;
            recognition.lang = 'en-US';

            recognition.onresult = function(event) {
                let interim = '';
                let finalTranscript = '';
                for (let i = event.resultIndex; i < event.results.length; ++i) {
                    const result = event.results[i];
                    if (result.isFinal) {
                        finalTranscript += result[0].transcript;
                    } else {
                        interim += result[0].transcript;
                    }
                }

                // Show interim results in the transcript panel
                if (interim) {
                    showInterim(interim);
                } else {
                    clearInterim();
                }

                if (finalTranscript) {
                    clearInterim();
                    const timestamp = new Date().toLocaleTimeString();
                    addTranscript(timestamp, 'You', finalTranscript);
                    sendTranscriptToServer(finalTranscript);
                }
            };

            recognition.onerror = function(evt) {
                console.error('Speech recognition error:', evt);
                updateStatus('Speech recognition error');
            };

            recognition.onend = function() {
                // If recording is still flagged, restart recognition (helps some browsers)
                if (isRecording) {
                    try { recognition.start(); } catch (e) { console.warn('Could not restart recognition', e); }
                }
            };
        } else {
            console.warn('Web Speech API not supported in this browser');
        }

        // Initialize WebSocket connection
        function initWebSocket() {
            websocket = new WebSocket('ws://localhost:8000/ws/transcript');

            websocket.onopen = function(event) {
                console.log('WebSocket connected');
                updateStatus('Connected to AI agent');
            };

            websocket.onmessage = function(event) {
                const data = JSON.parse(event.data);
                handleWebSocketMessage(data);
            };

            websocket.onclose = function(event) {
                console.log('WebSocket disconnected');
                updateStatus('Disconnected from AI agent');
            };

            websocket.onerror = function(error) {
                console.error('WebSocket error:', error);
                updateStatus('Connection error');
            };
        }

        // Handle incoming WebSocket messages
        function handleWebSocketMessage(data) {
            if (data.type === 'transcript') {
                addTranscript(data.timestamp || new Date().toLocaleTimeString(), 'Speaker', data.text);
            } else if (data.type === 'summary') {
                addSummary(data.text);
            }
        }

        // Show interim transcript text in UI
        const interimDiv = document.getElementById('interim');
        function showInterim(text) {
            if (!interimDiv) return;
            interimDiv.hidden = false;
            interimDiv.textContent = text;
        }

        function clearInterim() {
            if (!interimDiv) return;
            interimDiv.hidden = true;
            interimDiv.textContent = '';
        }

        // Improved status updater with levels
        function updateStatus(message, level = 'info') {
            statusDiv.textContent = message;
            statusDiv.classList.remove('recording', 'info', 'error');
            statusDiv.classList.add(level);
            if (isRecording) {
                statusDiv.classList.add('recording');
            }
        }

        // Send transcript to server
        function sendTranscriptToServer(transcript) {
            if (websocket && websocket.readyState === WebSocket.OPEN) {
                websocket.send(JSON.stringify({
                    type: 'transcript',
                    text: transcript,
                    timestamp: new Date().toISOString()
                }));
            }
        }

        // Update status display
        function updateStatus(message) {
            statusDiv.textContent = message;
            if (isRecording) {
                statusDiv.classList.add('recording');
            } else {
                statusDiv.classList.remove('recording');
            }
        }

        // Add transcript to display
        function addTranscript(timestamp, speaker, text) {
            const item = document.createElement('div');
            item.className = 'transcript-item';
            item.innerHTML = `
                <div class="timestamp">${timestamp}</div>
                <div class="speaker">${speaker}:</div>
                <div>${text}</div>
            `;
            transcriptDiv.appendChild(item);
            transcriptDiv.scrollTop = transcriptDiv.scrollHeight;
        }

        // Add note to display
        function addNote(timestamp, speaker, text, type = 'transcript') {
            const item = document.createElement('div');
            item.className = `note-item ${type}`;
            item.innerHTML = `
                <div class="timestamp">${timestamp}</div>
                <div class="speaker">${speaker}:</div>
                <div>${text}</div>
            `;
            notesDiv.appendChild(item);
            notesDiv.scrollTop = notesDiv.scrollHeight;
        }

        // Add summary note
        function addSummary(text) {
            const timestamp = new Date().toLocaleTimeString();
            addNote(timestamp, 'AI Summary', text, 'summary');
        }

        // Start meeting
        startMeetingBtn.addEventListener('click', function() {
            const title = meetingTitle.value || 'Untitled Meeting';
            if (websocket && websocket.readyState === WebSocket.OPEN) {
                websocket.send(JSON.stringify({
                    type: 'start_meeting',
                    title: title
                }));
                updateStatus(`Meeting started: ${title}`);
            }
        });

        // Toggle recording
        toggleRecordingBtn.addEventListener('click', async function() {
            if (!isRecording) {
                await startRecording();
            } else {
                stopRecording();
            }
        });

        // Start speech recognition
        async function startRecording() {
            try {
                if (!recognition) {
                    updateStatus('Speech recognition not available', 'error');
                    return;
                }

                recognition.start();
                isRecording = true;
                toggleRecordingBtn.textContent = '‚èπÔ∏è Stop Recording';
                toggleRecordingBtn.classList.add('recording');
                updateStatus('Listening...', 'info');

            } catch (error) {
                console.error('Error starting speech recognition:', error);
                updateStatus('Error: Could not start speech recognition', 'error');
                isRecording = false;
                toggleRecordingBtn.textContent = 'üé§ Start Recording';
                toggleRecordingBtn.classList.remove('recording');
            }
        }

        // Stop speech recognition
        function stopRecording() {
            if (recognition && isRecording) {
                recognition.stop();
                isRecording = false;
                toggleRecordingBtn.textContent = 'üé§ Start Recording';
                toggleRecordingBtn.classList.remove('recording');
                updateStatus('Speech recognition stopped');
            }
        }

        // Send audio to server
        function sendAudioToServer(audioBlob) {
            // Convert blob to base64 for sending
            const reader = new FileReader();
            reader.onloadend = function() {
                const base64Audio = reader.result.split(',')[1];
                if (websocket && websocket.readyState === WebSocket.OPEN) {
                    websocket.send(JSON.stringify({
                        type: 'audio',
                        audio: base64Audio
                    }));
                }
            };
            reader.readAsDataURL(audioBlob);
        }

        // Generate summary
        generateSummaryBtn.addEventListener('click', function() {
            if (websocket && websocket.readyState === WebSocket.OPEN) {
                websocket.send(JSON.stringify({
                    type: 'generate_summary'
                }));
                updateStatus('Generating summary...');
            }
        });

        // Export notes
        exportNotesBtn.addEventListener('click', function() {
            const notes = Array.from(document.querySelectorAll('.note-item')).map(item => {
                const timestamp = item.querySelector('.timestamp').textContent;
                const speaker = item.querySelector('.speaker').textContent;
                const text = item.querySelector('div:last-child').textContent;
                return `${timestamp} ${speaker} ${text}`;
            }).join('\n\n');

            const blob = new Blob([notes], { type: 'text/plain' });
            const url = URL.createObjectURL(blob);
            const a = document.createElement('a');
            a.href = url;
            a.download = `meeting_notes_${new Date().toISOString().split('T')[0]}.txt`;
            document.body.appendChild(a);
            a.click();
            document.body.removeChild(a);
            URL.revokeObjectURL(url);
        });

        // Export transcript
        exportTranscriptBtn.addEventListener('click', function() {
            const transcript = Array.from(document.querySelectorAll('.transcript-item')).map(item => {
                const timestamp = item.querySelector('.timestamp').textContent;
                const speaker = item.querySelector('.speaker').textContent;
                const text = item.querySelector('div:last-child').textContent;
                return `${timestamp} ${speaker} ${text}`;
            }).join('\n\n');

            const blob = new Blob([transcript], { type: 'text/plain' });
            const url = URL.createObjectURL(blob);
            const a = document.createElement('a');
            a.href = url;
            a.download = `meeting_transcript_${new Date().toISOString().split('T')[0]}.txt`;
            document.body.appendChild(a);
            a.click();
            document.body.removeChild(a);
            URL.revokeObjectURL(url);
        });

        // Initialize on page load
        window.addEventListener('load', function() {
            initWebSocket();
        });

        // Handle page unload
        window.addEventListener('beforeunload', function() {
            if (websocket) {
                websocket.close();
            }
            stopRecording();
        });
    </script>
</body>
</html>